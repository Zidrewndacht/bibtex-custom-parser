OK  Identify LLM by name from the API
OK  Remove bogus DOI links from papers that lack so.
OK  Change LLM endpoint URL to go to the server itself instead of /v1/chat/completions
        Ensure correct usage on all files.
OK  Use Config from file instead of requiring commandline

OK  Add column for "page count" (to filter out short papers)
OK  Add columns on DB for "verified by":         User        Computer        null
        Also add a tooltip for LLM namme
OK  Add new column to table and/or detail row:
OK      Verified by

OK  Add missing columns to table and/or detail row:
OK        Model name
OK        Page count
    
OK   Redo from scratch verification pass (LLM reads each DB line and checks if the according inferred values are sane)
OK      Use shared functions from globals.py

OK    Add support to reasoning models
OK        Save reasoning to DB
OK        Show reasoning in detail row

OK   Fix page count parser for Zotero exports

OK  Add client-side filters:
OK      Instant search keywords
OK            Ensure detail row still stays linked to corresponding article row
OK        Filter out short papers
OK        Filter out offtopic

OK    Add quick stats (totals at the end of the table)
OK        Also add counter of total papers and total filtered papers
OK    Remove signal handler + set_flags, etc. from automate_classification.py
OK    Change "changed by" to icon instead of model name, consistent with "verified by"
OK    Fix bogus table shading after filtering


    Import from GUI?
    Send to LLM from GUI
        Reprocess all?
        Reprocess remaining?
        Verify remaining
        "Classify this paper" from detail row?
        "Verify this paper" from detail row?
    Export stats to Excel?

    Try to import full text of papers?
        Maybe not, even if technically feasible, due to copyright concerns, etc.

    automate never reaches final status, stuck at 'processed 524/524' papers after finishing.
