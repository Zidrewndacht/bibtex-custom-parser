C:\llama.cpp\binaries\llama-server --model "C:\llama.cpp\models\Qwen3-30B-A3B-Instruct-2507-UD-Q4_K_XL.gguf" --n-gpu-layers 99 --jinja --no-mmap --ctx_size 120000 -np 24 --alias Qwen30b-A3b-Q4 --cache-reuse 256
pause
